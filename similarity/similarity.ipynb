{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ca1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to build a sentence vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c756cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world what a time to be alive!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d895a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pytorch and transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42462401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7477c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize tokenizer and the model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "237cb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "\n",
    "tokens = tokenizer.encode_plus(text, max_length=128, truncation=True, padding='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "362905fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fa6f905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 3.0681e-01, -7.8805e-02,  1.7431e+00,  ..., -2.5348e-02,\n",
       "          -1.1080e-01,  4.8310e-02],\n",
       "         [ 7.1302e-01,  1.0437e-01,  1.8346e+00,  ...,  1.1343e-01,\n",
       "          -7.5563e-02,  1.2668e-01],\n",
       "         [ 8.1722e-01,  1.1321e-01,  1.5408e+00,  ..., -3.8067e-01,\n",
       "           8.7479e-02, -1.9020e-01],\n",
       "         ...,\n",
       "         [ 5.4669e-01,  1.7181e-01,  1.1392e+00,  ...,  3.8549e-02,\n",
       "          -1.5396e-01,  2.3015e-01],\n",
       "         [ 3.4457e-01,  1.3151e-01,  1.1324e+00,  ..., -1.4217e-03,\n",
       "          -1.7517e-01,  1.5220e-01],\n",
       "         [ 3.2320e-01,  3.3350e-03,  1.1888e+00,  ...,  1.6736e-02,\n",
       "          -2.0864e-01,  8.9315e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-7.1334e-01, -2.7907e-01,  7.7808e-01, -1.9139e-01, -1.4626e-01,\n",
       "         -2.2970e-01,  4.3867e-01, -1.3565e-01,  4.1930e-01, -8.8569e-01,\n",
       "          3.7006e-01, -3.7974e-01,  7.3329e-01, -2.6172e-01,  8.7081e-01,\n",
       "         -3.7279e-01, -2.9780e-01, -2.1084e-01,  4.4356e-01, -2.2888e-01,\n",
       "          4.2236e-01,  5.5015e-01,  7.5253e-01,  1.1973e-01,  1.4079e-01,\n",
       "          3.6185e-02, -6.9850e-01,  8.9107e-01,  7.4306e-01,  7.1026e-01,\n",
       "         -6.9478e-01,  1.2284e-01, -9.4647e-01, -4.3430e-01,  2.9155e-02,\n",
       "         -9.3145e-01,  8.3090e-02, -7.7918e-01, -2.2681e-01,  2.9572e-02,\n",
       "         -9.1181e-01,  2.0583e-01,  7.7457e-01,  5.3129e-01, -2.9347e-02,\n",
       "          2.5664e-02, -9.4791e-01,  1.1471e-01, -8.2558e-01, -6.7865e-01,\n",
       "         -4.0155e-01, -8.7544e-01,  3.0248e-01,  4.5964e-01,  1.3376e-01,\n",
       "          7.0546e-01,  1.2989e-01,  8.0394e-02, -1.1799e-01, -4.8591e-01,\n",
       "         -5.6611e-01, -4.2842e-02,  1.0017e-01, -7.2991e-01, -5.8599e-01,\n",
       "         -5.8388e-01, -2.7178e-01, -3.2961e-01, -2.6831e-01,  3.7274e-01,\n",
       "          5.8541e-01,  9.1363e-02,  6.4759e-01, -9.1125e-01, -8.2260e-01,\n",
       "          3.2181e-01, -4.6633e-01,  9.9631e-01, -2.6347e-01, -9.4867e-01,\n",
       "          2.5284e-01, -7.9731e-01,  4.6151e-01,  4.3900e-01, -5.6762e-01,\n",
       "         -9.8465e-01, -1.2024e-02,  2.4155e-01, -9.4979e-01,  4.3475e-01,\n",
       "          3.9026e-01, -1.9735e-01,  4.1920e-01,  2.7546e-01,  1.3238e-01,\n",
       "         -3.5910e-01, -2.9062e-01, -4.0084e-01, -1.1532e-01,  8.5213e-02,\n",
       "          1.0904e-01, -1.9108e-01,  1.0203e-01, -3.7160e-01,  3.1496e-01,\n",
       "         -1.0087e-01, -2.9763e-01,  1.9633e-01, -5.0799e-01,  3.5502e-01,\n",
       "          1.8670e-01, -4.9766e-01,  6.1222e-01, -9.1405e-01,  2.2588e-01,\n",
       "         -4.1397e-01, -9.3591e-01, -4.6707e-01, -9.7126e-01,  4.9750e-02,\n",
       "         -5.4274e-02, -3.3579e-01,  6.9349e-01,  4.4322e-01,  1.4020e-01,\n",
       "         -2.5608e-01,  8.2508e-01, -9.9760e-01, -8.3655e-02, -4.9525e-01,\n",
       "          3.6698e-01, -1.5357e-01, -8.4281e-01, -9.5627e-01,  5.5757e-01,\n",
       "          9.0900e-01,  2.8112e-01,  8.0196e-01,  2.4870e-02,  7.5625e-01,\n",
       "          8.0252e-01, -1.1305e-01, -5.2113e-01, -3.5313e-01,  4.3727e-01,\n",
       "          2.0521e-01, -4.6751e-01,  4.0023e-01,  9.2862e-02, -4.7571e-01,\n",
       "         -1.3376e-01, -3.0775e-01,  4.0386e-01, -9.2449e-01, -3.7863e-01,\n",
       "          9.0531e-01, -2.4694e-01,  8.5297e-01,  8.0517e-01, -8.0454e-02,\n",
       "         -3.3122e-01,  6.5678e-01,  2.2172e-01,  3.5561e-01,  3.9816e-01,\n",
       "          2.8331e-01, -4.4261e-01,  3.3523e-01, -4.3983e-01,  5.4551e-01,\n",
       "          5.0914e-01, -5.2225e-01,  3.0285e-01, -8.9802e-01, -2.6078e-01,\n",
       "          3.1197e-02,  9.7227e-01,  1.5044e-01,  3.2500e-01, -8.0755e-01,\n",
       "         -3.0937e-01, -2.2491e-01, -9.1379e-01,  9.4299e-01, -3.3972e-01,\n",
       "          5.4836e-02,  5.1837e-01,  6.4941e-02, -7.4799e-01, -1.4749e-01,\n",
       "          5.1604e-02,  2.0521e-01, -6.4327e-01, -4.0954e-01, -4.4724e-01,\n",
       "         -3.5976e-01,  3.0445e-02,  1.4287e-01, -2.9038e-01, -5.1567e-01,\n",
       "         -5.9452e-01,  8.6022e-01,  4.8902e-01,  5.0969e-01, -1.9530e-01,\n",
       "          3.8906e-01, -7.8211e-01, -3.8403e-01,  1.7038e-01,  2.7750e-01,\n",
       "          5.1046e-01,  9.3446e-01,  1.7531e-01, -5.6885e-02, -7.6776e-01,\n",
       "         -8.9966e-01,  4.1484e-01, -6.0979e-01, -1.8620e-01, -7.5173e-01,\n",
       "         -3.6664e-02,  6.8659e-01, -7.1581e-01,  8.5388e-02, -8.8838e-01,\n",
       "         -4.8028e-01,  3.5951e-01,  5.9763e-02,  2.3166e-01, -3.4926e-01,\n",
       "          9.1038e-01,  2.8796e-01, -4.4759e-01,  6.2290e-01,  8.4603e-01,\n",
       "          8.9865e-02, -5.9918e-01,  4.8237e-01, -4.2858e-01,  3.7806e-01,\n",
       "         -5.9966e-01,  7.4322e-01,  2.6091e-01,  4.2949e-01, -6.5760e-01,\n",
       "          2.2159e-01, -5.4819e-01,  7.5705e-01, -3.1214e-01, -7.9634e-01,\n",
       "         -5.5659e-01,  4.3866e-01,  3.9189e-01,  4.0315e-01, -7.4680e-02,\n",
       "          7.6218e-01, -9.1573e-01, -9.3126e-01, -4.1753e-01,  4.1852e-01,\n",
       "         -9.2044e-01,  2.9709e-01,  5.4169e-01, -1.4895e-01, -2.9162e-01,\n",
       "         -2.0187e-01, -9.6991e-01,  7.7705e-01,  1.7013e-01,  7.1631e-01,\n",
       "         -2.4545e-01, -6.9448e-01,  1.6327e-01, -9.4167e-01,  2.0801e-01,\n",
       "          3.8624e-02,  3.8501e-01,  2.6562e-01, -9.2506e-01,  6.0992e-01,\n",
       "          5.8637e-01,  3.2532e-01,  7.2832e-01,  9.0453e-01,  8.8866e-01,\n",
       "          8.9561e-01,  8.0563e-01,  2.3359e-01, -5.3985e-01,  1.2731e-01,\n",
       "          8.9188e-01, -3.4723e-01, -9.7477e-01, -8.1505e-01, -4.5382e-01,\n",
       "          5.1102e-01, -9.9741e-01, -5.3145e-01, -1.7565e-01, -7.7451e-01,\n",
       "         -4.4605e-01,  7.9124e-01,  8.0038e-01, -9.9437e-01, -1.2302e-01,\n",
       "          8.4792e-01, -7.1488e-01, -1.9025e-01,  1.0772e-01,  9.3050e-01,\n",
       "          6.1820e-01,  3.8699e-01, -5.1764e-02,  2.0573e-01, -2.5669e-01,\n",
       "         -6.9219e-01,  2.8093e-01, -2.7291e-02, -2.1866e-01,  5.7252e-01,\n",
       "         -2.4601e-01, -7.9479e-01, -1.0683e-01, -4.6706e-01, -9.8495e-02,\n",
       "         -9.4668e-01, -3.8131e-01, -6.3950e-01,  3.8630e-01,  1.7043e-01,\n",
       "          1.0153e-01, -4.2449e-01,  4.3422e-01, -3.6688e-01,  2.7565e-01,\n",
       "          4.7452e-01, -8.5087e-01, -5.1454e-01, -7.2013e-01, -4.5425e-01,\n",
       "          4.0316e-01, -9.0178e-01,  7.9966e-01, -1.3460e-01, -7.8334e-01,\n",
       "          9.9774e-01, -3.5372e-01, -7.2405e-01, -2.1392e-01,  1.9982e-01,\n",
       "         -8.4063e-01,  9.9665e-01,  3.7683e-01, -8.9454e-01, -5.4307e-01,\n",
       "         -5.2452e-01, -5.6773e-02, -4.4963e-01,  5.4475e-01, -5.3048e-01,\n",
       "          4.9845e-01,  1.7400e-01,  9.2718e-01, -9.5800e-01, -9.4541e-02,\n",
       "         -6.7284e-01, -8.8123e-01,  7.3588e-01,  9.1792e-01, -1.9352e-01,\n",
       "         -4.4347e-01, -8.5831e-02,  3.5196e-01,  1.5183e-01, -8.2310e-01,\n",
       "          2.1703e-01,  5.3439e-02, -2.0038e-01,  8.8352e-01, -5.3860e-01,\n",
       "         -4.0572e-01,  4.3350e-01, -8.1622e-02,  4.2370e-01, -5.5624e-01,\n",
       "          5.2035e-02, -4.9454e-01,  1.0926e-01, -5.8529e-01, -3.1988e-01,\n",
       "         -8.4397e-01,  3.0112e-01,  9.9647e-01, -3.3604e-02, -3.3406e-01,\n",
       "          7.1307e-01, -1.4305e-01,  2.4818e-01,  1.3993e-01,  2.2002e-01,\n",
       "         -4.9350e-01, -2.9730e-02,  1.3053e-01, -6.6665e-01, -9.2181e-01,\n",
       "          8.7030e-01,  4.3216e-01, -2.3913e-01,  9.0681e-01, -6.3945e-02,\n",
       "          1.8369e-01, -2.7918e-01, -4.7437e-01,  1.3454e-01,  2.1046e-01,\n",
       "         -4.9842e-01,  9.4737e-01, -8.0832e-02,  5.0511e-01,  6.8498e-01,\n",
       "          6.2646e-01, -6.8643e-01, -7.5332e-02,  4.0720e-01, -9.4543e-01,\n",
       "         -3.2885e-01, -9.0265e-01,  9.6577e-01, -8.6348e-01,  4.6324e-01,\n",
       "          3.1371e-01,  5.7345e-02,  9.9224e-01,  8.8528e-04,  4.6355e-01,\n",
       "         -2.9178e-01,  4.6343e-01, -7.0087e-01, -5.3382e-01, -1.4296e-01,\n",
       "         -3.6462e-01,  6.1072e-01, -1.4090e-01,  5.7150e-01, -8.7376e-01,\n",
       "         -6.3450e-01, -4.0737e-01, -8.9081e-01, -8.6960e-01,  6.1673e-01,\n",
       "         -3.4161e-01,  2.1909e-01, -2.7432e-01,  8.1700e-02, -4.2039e-01,\n",
       "         -9.3537e-02, -3.2600e-01, -9.2229e-01,  8.6679e-01, -4.6182e-01,\n",
       "          2.5175e-01, -1.7896e-01,  5.3039e-01, -7.3390e-01,  8.1505e-01,\n",
       "          6.3488e-01,  3.4724e-01, -3.4549e-01, -6.4733e-01,  7.9713e-01,\n",
       "         -3.6539e-01,  5.7508e-01, -3.1952e-01,  9.9733e-01, -6.7472e-01,\n",
       "          4.8939e-01,  7.8439e-01,  4.2086e-01, -6.0650e-01,  4.2936e-01,\n",
       "          1.3392e-02,  4.9741e-01,  7.0466e-01,  6.8939e-01, -1.6026e-01,\n",
       "         -2.5898e-01,  1.9189e-01, -9.2597e-02, -7.7082e-01,  7.9359e-01,\n",
       "         -1.1023e-01,  4.4831e-01,  5.2349e-02,  3.2821e-01,  8.3242e-01,\n",
       "         -3.6189e-01, -8.8319e-02, -4.7199e-01,  2.0465e-02, -1.9310e-01,\n",
       "         -4.4165e-01,  9.8404e-01,  4.8164e-01, -3.9999e-01, -9.4464e-01,\n",
       "          6.0118e-01, -4.7357e-01,  8.5432e-01,  9.2550e-01, -4.0504e-01,\n",
       "          1.3368e-01,  8.6808e-02, -2.7847e-01,  5.5351e-01, -1.4999e-01,\n",
       "         -2.9631e-01, -3.0525e-02,  3.8154e-01,  8.1241e-01, -3.2065e-01,\n",
       "         -9.3530e-01, -5.6551e-01,  3.1554e-01, -7.6484e-01,  1.5592e-01,\n",
       "         -8.1307e-02,  4.6578e-02,  5.2612e-02,  5.9962e-01,  3.3860e-01,\n",
       "          5.4608e-01, -9.2589e-01, -3.1040e-01,  1.5510e-01,  9.4342e-01,\n",
       "          4.1091e-01, -3.6788e-01, -8.7728e-01, -6.0326e-01,  5.8156e-02,\n",
       "          5.9077e-01, -8.2256e-01,  9.3608e-01, -9.3715e-01,  9.3167e-02,\n",
       "          9.8069e-01,  4.3258e-01, -8.1375e-01, -6.9133e-02, -3.3178e-02,\n",
       "          2.8292e-01, -5.8962e-01,  4.7400e-01, -9.1925e-01, -5.7224e-01,\n",
       "         -4.1121e-01,  1.4845e-01, -3.5130e-01,  6.1739e-01, -1.7440e-03,\n",
       "          3.2388e-01, -3.9029e-01, -1.8952e-01, -5.9464e-02,  5.4396e-01,\n",
       "          7.5874e-01, -4.2265e-01, -1.4632e-01,  1.3438e-01,  1.0550e-01,\n",
       "         -7.9247e-01, -1.7697e-01, -3.2276e-01, -6.6750e-01,  3.5083e-01,\n",
       "         -9.9765e-01, -6.4732e-02, -8.4588e-01, -4.3138e-01,  7.8081e-01,\n",
       "          1.3954e-01, -2.8214e-01, -4.8695e-01,  4.8502e-01,  8.4034e-01,\n",
       "          5.9887e-01, -6.5109e-01,  8.2503e-01, -7.8666e-01,  2.9245e-01,\n",
       "         -1.7415e-01,  3.1419e-01,  2.8420e-02,  7.4979e-01, -1.4438e-01,\n",
       "          9.9733e-01,  2.3871e-01,  2.9807e-02, -8.6558e-01,  2.1286e-01,\n",
       "         -3.1039e-01,  8.6357e-01, -1.9709e-01, -9.0489e-01,  4.0505e-01,\n",
       "         -6.6564e-01, -7.6458e-01,  5.3811e-01,  3.4991e-01, -2.5717e-01,\n",
       "          9.2806e-02,  8.0804e-01,  5.3727e-01, -1.8905e-01,  2.9869e-01,\n",
       "         -2.7245e-01, -4.4316e-01,  4.0201e-02, -6.5552e-01,  9.7319e-01,\n",
       "          1.4842e-01,  4.4030e-01,  3.0459e-01, -2.9287e-01,  7.2908e-01,\n",
       "          4.4756e-01,  3.8865e-01,  2.4003e-01,  9.8816e-01,  3.7817e-01,\n",
       "         -9.1553e-01, -2.9635e-01, -8.7539e-01, -4.1966e-01, -9.4948e-01,\n",
       "          2.4677e-01,  3.3360e-01,  7.6693e-01, -3.7255e-01,  6.7884e-01,\n",
       "          8.3539e-01,  4.7109e-01,  4.5594e-01,  4.0944e-01,  1.6064e-01,\n",
       "         -7.5123e-01, -9.4811e-01, -9.4557e-01,  2.1827e-01, -2.0005e-01,\n",
       "         -3.0375e-01,  4.1853e-01,  3.8478e-01,  3.1583e-01,  4.1162e-01,\n",
       "         -9.8173e-01,  7.9341e-01,  3.6777e-01, -6.3777e-01,  9.0083e-01,\n",
       "          6.8574e-01,  3.2878e-01,  2.4278e-01, -9.6157e-01, -7.8184e-01,\n",
       "         -2.1130e-01, -1.1877e-01,  4.9302e-01,  4.7686e-01,  8.6120e-01,\n",
       "          2.5544e-01, -5.6586e-01, -2.3442e-01,  1.4947e-01, -8.4834e-01,\n",
       "         -9.8282e-01,  3.8087e-01,  8.5373e-01, -6.1769e-01,  9.5659e-01,\n",
       "         -5.2099e-01, -4.1349e-01,  6.4424e-01,  3.5750e-02,  7.7297e-01,\n",
       "          4.1232e-01,  6.7050e-01,  6.7988e-02,  3.0762e-01,  8.0780e-01,\n",
       "          7.2061e-01,  8.7522e-01,  2.2744e-01,  9.8657e-02,  7.9642e-01,\n",
       "          1.2527e-02,  8.3641e-01, -9.2276e-01,  4.2090e-01, -3.9081e-02,\n",
       "         -8.5823e-02,  1.6056e-01, -3.7656e-01, -8.3883e-01, -2.6764e-01,\n",
       "         -2.7820e-01,  5.6942e-01, -2.4776e-01,  9.2594e-02, -6.6908e-01,\n",
       "         -5.1733e-01, -2.2546e-01, -5.2972e-01,  5.6145e-01,  1.3699e-01,\n",
       "          8.7167e-01, -4.1065e-02, -5.0250e-01, -1.9179e-01, -9.7029e-02,\n",
       "          7.7296e-01, -9.0069e-01,  5.9224e-01, -4.0700e-01,  4.8355e-01,\n",
       "          4.5201e-01,  2.1957e-01,  5.2936e-02, -7.9352e-01, -7.3998e-02,\n",
       "         -1.8283e-01, -2.6384e-01,  3.1100e-01,  5.9525e-01, -4.2251e-01,\n",
       "         -6.1190e-01,  1.7774e-01,  4.9068e-01,  4.8679e-01,  7.7029e-01,\n",
       "          8.2344e-01,  3.3683e-01, -1.5561e-01,  3.4585e-01, -3.3398e-01,\n",
       "         -9.8084e-01,  4.1982e-01,  7.0505e-01, -2.0981e-01, -1.0285e-01,\n",
       "         -5.2072e-01,  6.0795e-01, -8.2681e-01, -4.0676e-01,  2.4043e-01,\n",
       "          2.4597e-01,  3.8303e-02,  1.0456e-01,  4.4530e-01,  9.0506e-01,\n",
       "          1.1404e-01,  6.4312e-01,  5.8093e-01,  5.9442e-01,  5.6610e-01,\n",
       "         -7.2445e-02, -4.0359e-01,  8.7575e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89baf964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract last hidden state tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "049deb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0681e-01, -7.8805e-02,  1.7431e+00,  ..., -2.5348e-02,\n",
       "          -1.1080e-01,  4.8310e-02],\n",
       "         [ 7.1302e-01,  1.0437e-01,  1.8346e+00,  ...,  1.1343e-01,\n",
       "          -7.5563e-02,  1.2668e-01],\n",
       "         [ 8.1722e-01,  1.1321e-01,  1.5408e+00,  ..., -3.8067e-01,\n",
       "           8.7479e-02, -1.9020e-01],\n",
       "         ...,\n",
       "         [ 5.4669e-01,  1.7181e-01,  1.1392e+00,  ...,  3.8549e-02,\n",
       "          -1.5396e-01,  2.3015e-01],\n",
       "         [ 3.4457e-01,  1.3151e-01,  1.1324e+00,  ..., -1.4217e-03,\n",
       "          -1.7517e-01,  1.5220e-01],\n",
       "         [ 3.2320e-01,  3.3350e-03,  1.1888e+00,  ...,  1.6736e-02,\n",
       "          -2.0864e-01,  8.9315e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e7843a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf4944",
   "metadata": {},
   "source": [
    "- To produce a dense vector we need to perform mean  pooling operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b8b0a",
   "metadata": {},
   "source": [
    "- We need to multiply each value in our embeddings tensor by its respective attention mask value so that we ignore non real tokens\n",
    "\n",
    "- Mask values are 0 and 1s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e4b81",
   "metadata": {},
   "source": [
    "- First resize the attention mask vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3847891",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01b9cbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3d9c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the attention mask vector to be the same as embeddings one\n",
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.shape).float() #gives an extra dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f9d3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b66d81bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "\n",
    "masked_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1cd5d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3068, -0.0788,  1.7431,  ..., -0.0253, -0.1108,  0.0483],\n",
       "         [ 0.7130,  0.1044,  1.8346,  ...,  0.1134, -0.0756,  0.1267],\n",
       "         [ 0.8172,  0.1132,  1.5408,  ..., -0.3807,  0.0875, -0.1902],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3da15e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3bd8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62c7503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4438d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = torch.clamp(mask.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d540d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61f39fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cfd2f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8bd549eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cf0ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"Standing on one's head at job interviews forms a lasting impression.\",\n",
    "    \"It took him a month to finish the meal.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9000fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three years later, the coffin was still full of Jello.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf8737a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary that will contain tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    #tokenize sentences and append it to a dictionary list\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=128, truncation=True,\n",
    "                                      padding='max_length', return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    \n",
    "#reformat a list of tensor into a single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "028ba72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e86a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57547139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65df9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85fcd0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1660e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.9230e-02,  6.2300e-01,  3.5369e-02,  ...,  8.0334e-01,\n",
       "           1.6314e+00,  3.2812e-01],\n",
       "         [ 3.6729e-02,  6.8419e-01,  1.9460e-01,  ...,  8.4759e-02,\n",
       "           1.4747e+00, -3.0080e-01],\n",
       "         [-1.2140e-02,  6.5431e-01, -7.2718e-02,  ..., -3.2600e-02,\n",
       "           1.7717e+00, -6.8121e-01],\n",
       "         ...,\n",
       "         [ 1.9532e-01,  1.1085e+00,  3.3905e-01,  ...,  1.2826e+00,\n",
       "           1.0114e+00, -7.2754e-02],\n",
       "         [ 9.0217e-02,  1.0288e+00,  3.2973e-01,  ...,  1.2940e+00,\n",
       "           9.8651e-01, -1.1125e-01],\n",
       "         [ 1.2404e-01,  9.7365e-01,  3.9329e-01,  ...,  1.1359e+00,\n",
       "           8.7685e-01, -1.0435e-01]],\n",
       "\n",
       "        [[-3.2124e-01,  8.2512e-01,  1.0554e+00,  ..., -1.8555e-01,\n",
       "           1.5169e-01,  3.9366e-01],\n",
       "         [-7.1457e-01,  1.0297e+00,  1.1217e+00,  ...,  3.3118e-02,\n",
       "           2.3820e-01, -1.5632e-01],\n",
       "         [-2.3522e-01,  1.1353e+00,  8.5941e-01,  ..., -4.3096e-01,\n",
       "          -2.7241e-02, -2.9676e-01],\n",
       "         ...,\n",
       "         [-5.4000e-01,  3.2365e-01,  7.8392e-01,  ...,  2.1861e-03,\n",
       "          -2.9941e-01,  2.6594e-01],\n",
       "         [-5.6429e-01,  3.1867e-01,  9.5759e-01,  ...,  3.4248e-02,\n",
       "          -3.0299e-01,  1.8783e-01],\n",
       "         [-5.1719e-01,  3.5987e-01,  9.3357e-01,  ...,  2.4326e-02,\n",
       "          -2.2319e-01,  1.6717e-01]],\n",
       "\n",
       "        [[-7.5756e-01,  8.3988e-01, -3.7922e-01,  ...,  1.2708e-01,\n",
       "           1.2514e+00,  1.3652e-01],\n",
       "         [-6.5908e-01,  7.6135e-01, -4.6619e-01,  ...,  2.2593e-01,\n",
       "           1.1289e+00, -3.6105e-01],\n",
       "         [-9.0070e-01,  6.7913e-01, -3.7775e-01,  ...,  1.1418e-01,\n",
       "           9.0801e-01, -1.8305e-01],\n",
       "         ...,\n",
       "         [-2.1578e-01,  5.4630e-01,  3.1171e-01,  ...,  1.8021e-01,\n",
       "           7.1693e-01, -6.7160e-02],\n",
       "         [-3.0920e-01,  4.8334e-01,  3.0211e-01,  ...,  2.2885e-01,\n",
       "           6.6559e-01, -9.3169e-02],\n",
       "         [-2.9402e-01,  4.6784e-01,  3.0949e-01,  ...,  2.7821e-01,\n",
       "           5.1436e-01, -1.0211e-01]],\n",
       "\n",
       "        [[-1.0246e-01,  9.7842e-01,  1.4798e+00,  ..., -6.7322e-01,\n",
       "          -1.3459e+00, -1.5414e-01],\n",
       "         [ 1.6459e-01,  1.1261e+00,  9.7448e-01,  ..., -8.2403e-01,\n",
       "          -1.5562e+00, -6.0396e-01],\n",
       "         [ 4.7917e-01,  9.7228e-01,  1.3746e+00,  ..., -9.8250e-01,\n",
       "          -1.3523e+00, -5.8834e-01],\n",
       "         ...,\n",
       "         [ 6.3124e-02,  3.3896e-01,  1.2718e+00,  ..., -3.9970e-01,\n",
       "          -1.1031e+00, -1.3408e-01],\n",
       "         [ 1.3678e-01,  4.4807e-01,  1.2677e+00,  ..., -3.7586e-01,\n",
       "          -1.0867e+00, -2.6922e-01],\n",
       "         [ 1.4712e-01,  3.7091e-01,  1.2411e+00,  ..., -3.6103e-01,\n",
       "          -1.1337e+00, -2.6628e-01]],\n",
       "\n",
       "        [[-6.9432e-02,  1.3936e-01,  7.9762e-01,  ...,  1.1904e-01,\n",
       "           9.8823e-01,  2.6582e-01],\n",
       "         [ 5.1373e-03, -5.3534e-02,  8.8652e-01,  ..., -2.0870e-01,\n",
       "           7.9596e-01,  2.9188e-02],\n",
       "         [-1.5181e-01,  1.4075e-02,  7.6035e-01,  ..., -2.6414e-01,\n",
       "           6.3991e-01, -1.5048e-01],\n",
       "         ...,\n",
       "         [-1.6340e-01, -5.6690e-02,  7.4140e-01,  ...,  2.4665e-01,\n",
       "           7.6735e-01,  7.6984e-02],\n",
       "         [-2.2222e-01,  1.7150e-03,  7.0698e-01,  ...,  2.1065e-01,\n",
       "           7.1550e-01,  7.8734e-02],\n",
       "         [-1.9339e-01,  2.5327e-02,  7.8219e-01,  ...,  1.7633e-01,\n",
       "           6.4733e-01,  5.0552e-02]],\n",
       "\n",
       "        [[-2.3620e-01,  8.5513e-01, -8.0395e-01,  ...,  6.1217e-01,\n",
       "           3.0030e-01, -1.4919e-01],\n",
       "         [-8.6804e-02,  9.5311e-01, -6.4188e-01,  ...,  7.8669e-01,\n",
       "           2.9603e-01, -7.3501e-01],\n",
       "         [-3.0156e-01,  1.0148e+00, -3.3798e-01,  ...,  8.6336e-01,\n",
       "           4.6253e-02, -3.6234e-01],\n",
       "         ...,\n",
       "         [-1.0904e-01,  6.3199e-01, -8.4330e-01,  ...,  7.4846e-01,\n",
       "           1.0252e-01,  1.4869e-02],\n",
       "         [ 7.2192e-03,  7.3466e-01, -7.6890e-01,  ...,  6.0643e-01,\n",
       "           1.2874e-01,  3.3142e-02],\n",
       "         [-1.1083e-01,  7.6055e-01, -4.4468e-01,  ...,  6.7188e-01,\n",
       "           1.0593e-01, -3.4445e-03]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed0f04",
   "metadata": {},
   "source": [
    "## Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3861864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6da8e094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f79997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4373139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "549d7c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0692,  0.6230,  0.0354,  ...,  0.8033,  1.6314,  0.3281],\n",
       "         [ 0.0367,  0.6842,  0.1946,  ...,  0.0848,  1.4747, -0.3008],\n",
       "         [-0.0121,  0.6543, -0.0727,  ..., -0.0326,  1.7717, -0.6812],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.3212,  0.8251,  1.0554,  ..., -0.1855,  0.1517,  0.3937],\n",
       "         [-0.7146,  1.0297,  1.1217,  ...,  0.0331,  0.2382, -0.1563],\n",
       "         [-0.2352,  1.1353,  0.8594,  ..., -0.4310, -0.0272, -0.2968],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.7576,  0.8399, -0.3792,  ...,  0.1271,  1.2514,  0.1365],\n",
       "         [-0.6591,  0.7614, -0.4662,  ...,  0.2259,  1.1289, -0.3611],\n",
       "         [-0.9007,  0.6791, -0.3778,  ...,  0.1142,  0.9080, -0.1830],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.1025,  0.9784,  1.4798,  ..., -0.6732, -1.3459, -0.1541],\n",
       "         [ 0.1646,  1.1261,  0.9745,  ..., -0.8240, -1.5562, -0.6040],\n",
       "         [ 0.4792,  0.9723,  1.3746,  ..., -0.9825, -1.3523, -0.5883],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.0694,  0.1394,  0.7976,  ...,  0.1190,  0.9882,  0.2658],\n",
       "         [ 0.0051, -0.0535,  0.8865,  ..., -0.2087,  0.7960,  0.0292],\n",
       "         [-0.1518,  0.0141,  0.7603,  ..., -0.2641,  0.6399, -0.1505],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.2362,  0.8551, -0.8040,  ...,  0.6122,  0.3003, -0.1492],\n",
       "         [-0.0868,  0.9531, -0.6419,  ...,  0.7867,  0.2960, -0.7350],\n",
       "         [-0.3016,  1.0148, -0.3380,  ...,  0.8634,  0.0463, -0.3623],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8be2138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17d55cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a99fde64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11633d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b2f887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0745,  0.8637,  0.1795,  ...,  0.7734,  1.7247, -0.1803],\n",
       "        [-0.3715,  0.9729,  1.0840,  ..., -0.2552, -0.2759,  0.0358],\n",
       "        [-0.5030,  0.7950, -0.1240,  ...,  0.1441,  0.9704, -0.1791],\n",
       "        [-0.0132,  0.9773,  1.4516,  ..., -0.8462, -1.4004, -0.4118],\n",
       "        [-0.2019,  0.0597,  0.8603,  ..., -0.0100,  0.8431, -0.0841],\n",
       "        [-0.2131,  1.0175, -0.8833,  ...,  0.7371,  0.1947, -0.3011]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1082c02",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ebe190d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d178647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3308892 , 0.7219259 , 0.17475471, 0.44709635, 0.5548363 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "# calculate\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4707d4",
   "metadata": {},
   "source": [
    "### With the sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f243094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_name = 'bert-base-nli-mean-tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "620a7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8163f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b2efd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6712d6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07446156,  0.86369616,  0.17946291, ...,  0.77344   ,\n",
       "         1.7247493 , -0.1802747 ],\n",
       "       [-0.37146357,  0.97290134,  1.0839922 , ..., -0.25521314,\n",
       "        -0.27593705,  0.03575896],\n",
       "       [-0.50298285,  0.79498583, -0.12402609, ...,  0.14406338,\n",
       "         0.9703752 , -0.179116  ],\n",
       "       [-0.01324293,  0.97728604,  1.4515941 , ..., -0.84616524,\n",
       "        -1.4004319 , -0.41184407],\n",
       "       [-0.20192575,  0.05970386,  0.8602744 , ..., -0.01000801,\n",
       "         0.84306234, -0.08407753],\n",
       "       [-0.21311863,  1.017493  , -0.88327694, ...,  0.7371028 ,\n",
       "         0.1946914 , -0.30111343]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4ba4fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 768)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e32bd9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3308892 , 0.7219259 , 0.17475471, 0.44709635, 0.5548363 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [embeddings[0]],\n",
    "    embeddings[1:]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be94c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
